{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b06a84d-367c-4828-93d4-33652f3ffaac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starte Hashtag Scraper (clockworks/tiktok-scraper)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m[apify.tiktok-scraper runId:GT5jSWUBkBalTFrkS]\u001b[0m -> Status: RUNNING, Message: \n",
      "\u001b[36m[apify.tiktok-scraper runId:GT5jSWUBkBalTFrkS]\u001b[0m -> 2025-11-20T11:54:02.137Z ACTOR: Pulling container image of build tSYT1F9Ve8ZomN7ZM from registry.\n",
      "\u001b[36m[apify.tiktok-scraper runId:GT5jSWUBkBalTFrkS]\u001b[0m -> 2025-11-20T11:54:02.141Z ACTOR: Creating container.\n",
      "\u001b[36m[apify.tiktok-scraper runId:GT5jSWUBkBalTFrkS]\u001b[0m -> 2025-11-20T11:54:02.184Z ACTOR: Starting container.\n",
      "\u001b[36m[apify.tiktok-scraper runId:GT5jSWUBkBalTFrkS]\u001b[0m -> 2025-11-20T11:54:02.592Z Will run command: xvfb-run -a -s \"-ac -screen 0 1920x1080x24+32 -nolisten tcp\" /bin/sh -c ./start_xvfb_and_run_cmd.sh && npm run start:prod --silent\n",
      "\u001b[36m[apify.tiktok-scraper runId:GT5jSWUBkBalTFrkS]\u001b[0m -> 2025-11-20T11:54:03.952Z \u001b[32mINFO\u001b[39m  System info\u001b[90m {\"apifyVersion\":\"3.4.2\",\"apifyClientVersion\":\"2.12.6\",\"crawleeVersion\":\"3.13.9\",\"osType\":\"Linux\",\"nodeVersion\":\"v20.19.5\"}\u001b[39m\n",
      "\u001b[36m[apify.tiktok-scraper runId:GT5jSWUBkBalTFrkS]\u001b[0m -> Status: RUNNING, Message: Starting the crawler.\n",
      "\u001b[36m[apify.tiktok-scraper runId:GT5jSWUBkBalTFrkS]\u001b[0m -> 2025-11-20T11:54:04.921Z \u001b[32mINFO\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Starting the crawler.\n",
      "\u001b[36m[apify.tiktok-scraper runId:GT5jSWUBkBalTFrkS]\u001b[0m -> 2025-11-20T11:54:08.151Z \u001b[32mINFO\u001b[39m  [HASHTAG_CONTINUATION] Scraped 30 videos --- https://www.tiktok.com/tag/tiktokmademebuyit\n",
      "\u001b[36m[apify.tiktok-scraper runId:GT5jSWUBkBalTFrkS]\u001b[0m -> 2025-11-20T11:54:08.508Z \u001b[32mINFO\u001b[39m  [HASHTAG_CONTINUATION] Scraped 30 videos --- https://www.tiktok.com/tag/tiktokmademebuyit\n",
      "\u001b[36m[apify.tiktok-scraper runId:GT5jSWUBkBalTFrkS]\u001b[0m -> 2025-11-20T11:54:09.162Z \u001b[32mINFO\u001b[39m  [HASHTAG_CONTINUATION] Scraped 20 videos --- https://www.tiktok.com/tag/tiktokmademebuyit\n",
      "\u001b[36m[apify.tiktok-scraper runId:GT5jSWUBkBalTFrkS]\u001b[0m -> 2025-11-20T11:54:10.422Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. Failed to send API request with exit code, retrying\n",
      "\u001b[36m[apify.tiktok-scraper runId:GT5jSWUBkBalTFrkS]\u001b[0m -> 2025-11-20T11:54:10.424Z     at async sendCurlRequest (file:///home/myuser/dist/src/tools/api/curl-request.js:25:43)\u001b[90m {\"id\":\"8QLyzLa7xDXyvpA\",\"url\":\"https://www.tiktok.com/tag/tiktokmademebuyit\",\"retryCount\":1}\u001b[39m\n",
      "\u001b[36m[apify.tiktok-scraper runId:GT5jSWUBkBalTFrkS]\u001b[0m -> Status: RUNNING, Message: Crawled 5/6 pages, 0 failed requests, desired concurrency 10.\n",
      "\u001b[36m[apify.tiktok-scraper runId:GT5jSWUBkBalTFrkS]\u001b[0m -> 2025-11-20T11:54:14.785Z \u001b[32mINFO\u001b[39m  [Status message]: Scraped 1/1 hashtags\n",
      "\u001b[36m[apify.tiktok-scraper runId:GT5jSWUBkBalTFrkS]\u001b[0m -> 2025-11-20T11:54:16.183Z \u001b[32mINFO\u001b[39m  [HASHTAG_CONTINUATION] Scraped 20 videos --- https://www.tiktok.com/tag/tiktokmademebuyit\n",
      "\u001b[36m[apify.tiktok-scraper runId:GT5jSWUBkBalTFrkS]\u001b[0m -> 2025-11-20T11:54:16.185Z \u001b[32mINFO\u001b[39m  [HASHTAG_CONTINUATION] No more videos to scrape. --- https://www.tiktok.com/tag/tiktokmademebuyit\n",
      "\u001b[36m[apify.tiktok-scraper runId:GT5jSWUBkBalTFrkS]\u001b[0m -> 2025-11-20T11:54:16.260Z \u001b[32mINFO\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m All requests from the queue have been processed, the crawler will shut down.\n",
      "\u001b[36m[apify.tiktok-scraper runId:GT5jSWUBkBalTFrkS]\u001b[0m -> 2025-11-20T11:54:16.411Z \u001b[32mINFO\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Final request statistics:\u001b[90m {\"requestsFinished\":6,\"requestsFailed\":0,\"retryHistogram\":[5,1],\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":3047,\"requestsFinishedPerMinute\":31,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":18281,\"requestsTotal\":6,\"crawlerRuntimeMillis\":11686}\u001b[39m\n",
      "\u001b[36m[apify.tiktok-scraper runId:GT5jSWUBkBalTFrkS]\u001b[0m -> 2025-11-20T11:54:16.413Z \u001b[32mINFO\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Finished! Total 6 requests: 6 succeeded, 0 failed.\u001b[90m {\"terminal\":true}\u001b[39m\n",
      "\u001b[36m[apify.tiktok-scraper runId:GT5jSWUBkBalTFrkS]\u001b[0m -> Status: RUNNING, Message: Scraped 1/1 hashtags. Starting media download.\n",
      "\u001b[36m[apify.tiktok-scraper runId:GT5jSWUBkBalTFrkS]\u001b[0m -> 2025-11-20T11:54:16.425Z \u001b[32mINFO\u001b[39m  [Status message]: Scraped 1/1 hashtags. Starting media download.\n",
      "\u001b[36m[apify.tiktok-scraper runId:GT5jSWUBkBalTFrkS]\u001b[0m -> 2025-11-20T11:54:21.457Z \u001b[32mINFO\u001b[39m  Starting media download. This might take a while.\n",
      "\u001b[36m[apify.tiktok-scraper runId:GT5jSWUBkBalTFrkS]\u001b[0m -> 2025-11-20T11:54:21.558Z \u001b[32mINFO\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Starting the crawler.\n",
      "\u001b[36m[apify.tiktok-scraper runId:GT5jSWUBkBalTFrkS]\u001b[0m -> 2025-11-20T11:54:22.004Z \u001b[32mINFO\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m All requests from the queue have been processed, the crawler will shut down.\n",
      "\u001b[36m[apify.tiktok-scraper runId:GT5jSWUBkBalTFrkS]\u001b[0m -> 2025-11-20T11:54:22.199Z \u001b[32mINFO\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Final request statistics:\u001b[90m {\"requestsFinished\":10,\"requestsFailed\":0,\"retryHistogram\":[10],\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":286,\"requestsFinishedPerMinute\":105,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":2856,\"requestsTotal\":10,\"crawlerRuntimeMillis\":5741}\u001b[39m\n",
      "\u001b[36m[apify.tiktok-scraper runId:GT5jSWUBkBalTFrkS]\u001b[0m -> 2025-11-20T11:54:22.201Z \u001b[32mINFO\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Finished! Total 10 requests: 10 succeeded, 0 failed.\u001b[90m {\"terminal\":true}\u001b[39m\n",
      "\u001b[36m[apify.tiktok-scraper runId:GT5jSWUBkBalTFrkS]\u001b[0m -> 2025-11-20T11:54:22.218Z \u001b[32mINFO\u001b[39m  Media download crawler has finished.\n",
      "\u001b[36m[apify.tiktok-scraper runId:GT5jSWUBkBalTFrkS]\u001b[0m -> Status: RUNNING, Message: Finished! Total 10 requests: 10 succeeded, 0 failed.\n",
      "\u001b[36m[apify.tiktok-scraper runId:GT5jSWUBkBalTFrkS]\u001b[0m -> 2025-11-20T11:54:22.326Z \u001b[32mINFO\u001b[39m  [Status message]: Scraped 1/1 hashtags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fertig! Dataset ID: AmILhHI4Rjygq9Lnk\n",
      "üìä Gefundene Videos: 10\n",
      "\n",
      "--- VIRAL VIDEO CHECK ---\n",
      "Beschreibung: #dollartree #craftorganization #tiktokmademebuyit #paintorganization #acrylicpaint #smallbusiness #diy #fyp\n",
      "Views: 3600000\n",
      "Likes: 294800\n",
      "Shares: 16700\n",
      "Video URL: N/A\n",
      "Cover Bild: https://api.apify.com/v2/key-value-stores/MpJW6brkMpte6a51I/records/cover-cutebyke-20220608150957-7106886660419259690.jpg\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from apify_client import ApifyClient\n",
    "\n",
    "TOKEN = ''\n",
    "\n",
    "def main() -> None:\n",
    "    client = ApifyClient(token=TOKEN)\n",
    "    \n",
    "    # ID aus deinem PDF (Seite 1 unten)\n",
    "    ACTOR_ID = 'clockworks/tiktok-scraper'\n",
    "\n",
    "    # Strategie: Wir suchen nach \"TikTok Made Me Buy It\", um Produkte zu finden\n",
    "    run_input = {\n",
    "        \"hashtags\": [\"tiktokmademebuyit\"], # Der Filter f√ºr Produkte!\n",
    "        \"resultsPerPage\": 10,              # Sicherheits-Limit\n",
    "        \"proxyCountryCode\": \"None\",        # Oder \"US\" falls n√∂tig\n",
    "        \"shouldDownloadVideos\": False,     # Spart Datenvolumen (wir nehmen nur den Link)\n",
    "        \"shouldDownloadCovers\": True       # Vorschaubilder f√ºr dein Dashboard\n",
    "    }\n",
    "\n",
    "    print(f\"üöÄ Starte Hashtag Scraper ({ACTOR_ID})...\")\n",
    "\n",
    "    try:\n",
    "        run = client.actor(ACTOR_ID).call(run_input=run_input, timeout_secs=180)\n",
    "\n",
    "        if run:\n",
    "            print(f\"‚úÖ Fertig! Dataset ID: {run['defaultDatasetId']}\")\n",
    "            dataset_items = client.dataset(run['defaultDatasetId']).list_items().items\n",
    "            print(f\"üìä Gefundene Videos: {len(dataset_items)}\")\n",
    "            \n",
    "            if dataset_items:\n",
    "                first = dataset_items[0]\n",
    "                print(\"\\n--- VIRAL VIDEO CHECK ---\")\n",
    "                # Mapping f√ºr dein Dashboard:\n",
    "                print(f\"Beschreibung: {first.get('text', 'N/A')}\")\n",
    "                # Metriken f√ºr \"Winning Product\" Erkennung:\n",
    "                print(f\"Views: {first.get('playCount', 'N/A')}\")\n",
    "                print(f\"Likes: {first.get('diggCount', 'N/A')}\")\n",
    "                print(f\"Shares: {first.get('shareCount', 'N/A')}\")\n",
    "                # Medien f√ºr die Ad-Card:\n",
    "                print(f\"Video URL: {first.get('videoMeta', {}).get('downloadAddr', 'N/A')}\")\n",
    "                print(f\"Cover Bild: {first.get('videoMeta', {}).get('coverUrl', 'N/A')}\")\n",
    "                print(\"-------------------------\")\n",
    "                \n",
    "                with open(\"mock_data_tiktok_hashtag.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "                    json.dump(dataset_items, f, indent=4, ensure_ascii=False)\n",
    "        else:\n",
    "            print(\"‚ùå Keine Daten.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Fehler: {e}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a62672d-a3c5-45c2-a2ad-b0bffbde73b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
